{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOuTJs0piRKSlT8duAjXTS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","**write a machine learning code in python-loading data from a file and normalization operation**"],"metadata":{"id":"lp7B8xz0j1yu"}},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load data from a file (replace 'data.csv' with your file path)\n","data = pd.read_csv('/content/organizations-100.csv')\n","\n","# Separate the target variable (if applicable)\n","# Example: Assuming the target variable is in a column named 'target'\n","# y = data['target']\n","# X = data.drop(columns=['target'])\n","\n","# Identify non-numeric columns and exclude them from scaling\n","non_numeric_cols = data.select_dtypes(exclude=[np.number]).columns\n","data_numeric = data.drop(columns=non_numeric_cols)\n","\n","# Initialize the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Normalize the numeric data\n","normalized_data = scaler.fit_transform(data_numeric)\n","\n","# Create a DataFrame from the normalized data (if needed)\n","normalized_df = pd.DataFrame(normalized_data, columns=data_numeric.columns)\n","\n","# Merge the non-numeric columns back into the DataFrame\n","for col in non_numeric_cols:\n","    normalized_df[col] = data[col]\n","\n","# Print the first few rows of the normalized data (optional)\n","print(normalized_df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFmT7mFwiT7f","executionInfo":{"status":"ok","timestamp":1696773122011,"user_tz":-330,"elapsed":415,"user":{"displayName":"01fe21bec357","userId":"03822722027900044309"}},"outputId":"5d565177-4b94-46ac-f7f9-49f4be32c7c5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["      Index   Founded  Number of employees  Organization Id  \\\n","0  0.000000  0.392157             0.334256  FAB0d41d5b5d22c   \n","1  0.010101  0.882353             0.483246  6A7EdDEA9FaDC52   \n","2  0.020202  0.019608             0.517574  0bFED1ADAE4bcC1   \n","3  0.030303  0.666667             0.070192  2bFC1Be8a4ce42f   \n","4  0.040404  0.411765             0.782252  9eE8A6a4Eb96C24   \n","\n","                      Name                         Website           Country  \\\n","0              Ferrell LLC              https://price.net/  Papua New Guinea   \n","1  Mckinney, Riley and Day  http://www.hall-buchanan.info/           Finland   \n","2               Hester Ltd       http://sullivan-reed.com/             China   \n","3           Holder-Sellers             https://becker.com/      Turkmenistan   \n","4              Mayer Group          http://www.brewer.com/         Mauritius   \n","\n","                                      Description                     Industry  \n","0             Horizontal empowering knowledgebase                     Plastics  \n","1             User-centric system-worthy leverage  Glass / Ceramics / Concrete  \n","2                  Switchable scalable moratorium                Public Safety  \n","3  De-engineered systemic artificial intelligence                   Automotive  \n","4              Synchronized needs-based challenge               Transportation  \n"]}]},{"cell_type":"markdown","source":["**Normalizing an Array Using the normalize() Function**"],"metadata":{"id":"91zaFNexlXvA"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import numpy as np\n","\n","x_array = np.array([2,3,5,6,7,4,8,7,6])\n","\n","normalized_arr = preprocessing.normalize([x_array])\n","print(normalized_arr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrO6UrT_kCws","executionInfo":{"status":"ok","timestamp":1696773526572,"user_tz":-330,"elapsed":5,"user":{"displayName":"01fe21bec357","userId":"03822722027900044309"}},"outputId":"9c6333aa-cae1-4369-9c68-d9296591335b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.11785113 0.1767767  0.29462783 0.35355339 0.41247896 0.23570226\n","  0.47140452 0.41247896 0.35355339]]\n"]}]},{"cell_type":"markdown","source":["**Normalizing Datasets by Row or by Column Using the normalize() Function**"],"metadata":{"id":"TskEzoFQlvcs"}},{"cell_type":"markdown","source":["https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing"],"metadata":{"id":"DHHnsROWmFSh"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","import pandas as pd\n","\n","from sklearn.datasets import fetch_california_housing\n","california_housing = fetch_california_housing(as_frame=True)\n","\n","d = preprocessing.normalize(california_housing.data)\n","scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)\n","print(scaled_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVDuMty7lfQx","executionInfo":{"status":"ok","timestamp":1696773602744,"user_tz":-330,"elapsed":2241,"user":{"displayName":"01fe21bec357","userId":"03822722027900044309"}},"outputId":"bbd4831b-f02d-484f-cd61-ed6738f1482f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n","0      0.023848  0.117447  0.020007   0.002933    0.922391  0.007321   \n","1      0.003452  0.008734  0.002594   0.000404    0.998535  0.000877   \n","2      0.014092  0.100971  0.016093   0.002084    0.963106  0.005441   \n","3      0.009816  0.090449  0.010119   0.001866    0.970590  0.004432   \n","4      0.006612  0.089394  0.010799   0.001859    0.971303  0.003750   \n","...         ...       ...       ...        ...         ...       ...   \n","20635  0.001825  0.029242  0.005902   0.001326    0.988384  0.002995   \n","20636  0.006753  0.047539  0.016147   0.003475    0.940212  0.008247   \n","20637  0.001675  0.016746  0.005128   0.001103    0.991926  0.002291   \n","20638  0.002483  0.023932  0.007086   0.001558    0.985188  0.002823   \n","20639  0.001715  0.011486  0.003772   0.000834    0.995727  0.001879   \n","\n","       Latitude  Longitude  \n","0      0.108510  -0.350136  \n","1      0.015745  -0.050829  \n","2      0.073495  -0.237359  \n","3      0.065837  -0.212643  \n","4      0.065069  -0.210162  \n","...         ...        ...  \n","20635  0.046179  -0.141637  \n","20636  0.104295  -0.320121  \n","20637  0.038840  -0.119405  \n","20638  0.052424  -0.161300  \n","20639  0.028264  -0.087038  \n","\n","[20640 rows x 8 columns]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"6XumPtvvmIv5"}}]}